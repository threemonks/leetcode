# /*
#  * Our team wants to create a new system to graph time series data
#  * of events occurring on Twitter so we can visually monitor health
#  * and throughput of Twitter systems. Our task is to create a library
#  * that will be called by other systems for both recording these
#  * events and also to query these events. Events generated by these
#  * other systems will be done in real-time, consisting of an event
#  * name and a Unix timestamp in milliseconds. This library should be
#  * fast and memory efficient.
#  *
#  * Example events:
#  *
#  * "com.twitter.tweet.like",    1603741739123  // 26 Oct 2020 12:48:59.123
#  * "com.twitter.tweet.like",    1603741706568  // 26 Oct 2020 12:48:26.568
#  * "com.twitter.tweet.like",    1603741813000  // 26 Oct 2020 12:50:13
#  * "com.twitter.tweet.retweet", 1603741788000  // 26 Oct 2020 12:49:48
#  * "com.twitter.tweet.sent",    1603741788753  // 26 Oct 2020 12:49:48.753
#  * "com.twitter.tweet.delete",  1603741814413  // 26 Oct 2020 12:50:14.413
#  *
#  * Additionally, our library needs to expose a way to query the counts
#  * of these events, e.g. to be displayed in a visual distribution
#  * graph, given a granularity (counts by minute, hour or day), the
#  * event name, and start and end time as Unix timestamps.
#  *
#  * Example Query:
#  *
#  *   - eventName = "com.twitter.tweet.like"
#  *   - granularity = MINUTE
#  *   - startTime = 1603741680000 // 26 Oct 2020 12:48:00
#  *   - endTime   = 1603741860000 // 26 Oct 2020 12:51:00
#  *
#  * Example graph:
#  *  ___
#  * | 2 |        ___
#  * |   |  ___  | 1 |
#  * ==================
#  * 12:48 12:49 12:50
#  *
#  * Example return value:
#  *
#  * {
#  *     1603741680000 -> 2
#  *     1603741740000 -> 0
#  *     1603741800000 -> 1
#  * }
#  *
#  */
"""
{eventname: [count]}
24*60*365*100 =
time query O((endTime-startTime)/(60*1000))
"""
MAX_SIZE = 24 * 60 * 365 * 1
EPOCH_TIME = 1603741680000  # // 26 Oct 2001 12:49:48
MS_MIN = 60 * 1000
from collections import defaultdict


class EventLogger:
    def __init__(self):
        self.data = dict()

    def record(self, eventname, eventtime):
        event_min = int((eventtime - EPOCH_TIME) / MS_MIN)
        if eventname in self.data:
            self.data[eventname][event_min] += 1
        else:
            self.data[eventname] = [0 for _ in range(MAX_SIZE)]
            self.data[eventname][event_min] += 1

    def query(self, eventname, granularity, startTime, endTime):
        if eventname not in self.data:
            return {}

        counts = self.data[eventname]
        res = {}
        start_min = int((startTime - EPOCH_TIME) / MS_MIN)
        end_min = int((endTime - EPOCH_TIME) / MS_MIN)
        if granularity == 'MINUTE':
            for t in range(start_min, end_min):
                t_ms = t * MS_MIN + EPOCH_TIME
                res[t_ms] = counts[t]
        elif granularity == 'HOUR':
            hour_res = defaultdict(int)
            for t in range(start_min, end_min):
                t_h = int(t / 60)
                hour_res[t_h] += counts[t]
            # conver t_h => micro seconds since epoch time
            res = {}
            for k, v in hour_res.items():
                t_ms = k * 60 * MS_MIN + EPOCH_TIME
                res[t_ms] = v

        print(res)
        return res


testdata = [
    ["com.twitter.tweet.like", 1603741739123],  # 26 Oct 2020 12:48:59.123
    ["com.twitter.tweet.like", 1603741706568],  # 26 Oct 2020 12:48:26.568
    ["com.twitter.tweet.like", 1603741813000],  # 26 Oct 2020 12:50:13
    ["com.twitter.tweet.retweet", 1603741788000],  # 26 Oct 2020 12:49:48
    ["com.twitter.tweet.sent", 1603741788753],  # 26 Oct 2020 12:49:48.753
    ["com.twitter.tweet.delete", 1603741814413],  # 26 Oct 2020 12:50:14.413
]

#  *   - eventName = "com.twitter.tweet.like"
#  *   - granularity = MINUTE
#  *   - startTime = 1603741680000 // 26 Oct 2020 12:48:00
#  *   - endTime   = 1603741860000 // 26 Oct 2020 12:51:00


#  * {
#  *     1603741680000 -> 2
#  *     1603741740000 -> 0
#  *     1603741800000 -> 1
#  * }


eventlogger = EventLogger()
for data in testdata:
    eventlogger.record(data[0], data[1])

assert eventlogger.query("com.twitter.tweet.like", "MINUTE", 1603741680000, 1603741860000) == {
    1603741680000: 2,
    1603741740000: 0,
    1603741800000: 1
}, 'fails'
